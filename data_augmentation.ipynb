{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4d7a50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "95975b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(path):\n",
    "    try:\n",
    "        with open(path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "64e524c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(path):\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            data = file.read()\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error decoding JSON in file: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6878b7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_adjacent_paragraphs(text):\n",
    "    pairs = []\n",
    "    paragraphs = text.split('\\n')\n",
    "    \n",
    "    for i in range(len(paragraphs)-1):\n",
    "        pairs.append(paragraphs[i+1] + '\\n' + paragraphs[i])\n",
    "        \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1c877353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jump_same_author_paragraphs(text, metadata):\n",
    "    pairs = []\n",
    "    paragraphs = text.split('\\n')\n",
    "    changes = metadata['changes']\n",
    "    changes_len = len(changes)\n",
    "    \n",
    "    if changes_len <= 1:\n",
    "        return []\n",
    "    \n",
    "    i = 0\n",
    "    while i < changes_len:\n",
    "        j = i+1\n",
    "        while j < changes_len and changes[i] == 0 and changes[j] == 0:\n",
    "            pairs.append(paragraphs[i] + '\\n' + paragraphs[j+1])\n",
    "            j += 1\n",
    "        i += 1\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e4d48b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_different_author_paragraphs(text, metadata):\n",
    "    pairs = []\n",
    "    paragraphs = text.split('\\n')\n",
    "    authors = metadata['authors']\n",
    "    paragraphs_len = len(paragraphs)\n",
    "    \n",
    "    if paragraphs_len <= 2 or authors < paragraphs_len:\n",
    "        return []\n",
    "    \n",
    "    for i in range(paragraphs_len):\n",
    "        for j in range(i+2, paragraphs_len):\n",
    "            pairs.append(paragraphs[i] + '\\n' + paragraphs[j])\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "924c7d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EASY_DIR = './data/easy/train/'\n",
    "MEDIUM_DIR = './data/medium/train/'\n",
    "HARD_DIR = './data/hard/train/'\n",
    "DIFFICULTY_DIRS = [EASY_DIR, MEDIUM_DIR, HARD_DIR]\n",
    "\n",
    "AUGMENTED_DIRS = ['./augmented/easy/train/', './augmented/medium/train/', './augmented/hard/train/'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d00d7d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_counter = [10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2bf153d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_file(file_dir, text, metadata):\n",
    "    text_file_path = file_dir + f'problem-{new_file_counter[0]}.txt'\n",
    "    metadata_file_path = file_dir + f'truth-problem-{new_file_counter[0]}.json'\n",
    "    \n",
    "    new_file_counter[0] += 1\n",
    "    \n",
    "    with open(text_file_path, 'w', encoding='utf-8') as text_file:\n",
    "        text_file.write(text)\n",
    "        \n",
    "    with open(metadata_file_path, 'w') as metadata_file:\n",
    "        json.dump(metadata, metadata_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "00627078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_metadata(authors, changes):\n",
    "    return {\n",
    "        'authors': authors,\n",
    "        'changes': changes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "840598bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_data_augmentation():\n",
    "    for original_dir, augmented_dir in zip(DIFFICULTY_DIRS, AUGMENTED_DIRS):\n",
    "        files = os.listdir(original_dir)\n",
    "        problems = [problem for problem in files if problem[0] == 'p']\n",
    "        truths = [truth for truth in files if truth[0] == 't']\n",
    "        \n",
    "        if not os.path.exists(augmented_dir):\n",
    "            os.makedirs(augmented_dir)\n",
    "\n",
    "        for i in range(len(problems)):\n",
    "            # TODO: remove `if` for original execution\n",
    "            if i > 5:\n",
    "                break\n",
    "            \n",
    "            text_file_name = original_dir + problems[i]\n",
    "            metadata_file_name = original_dir + truths[i]\n",
    "\n",
    "            text = read_text(text_file_name)\n",
    "            metadata = read_metadata(metadata_file_name)\n",
    "            changes = metadata['changes']\n",
    "            \n",
    "            swapped = swap_adjacent_paragraphs(text)\n",
    "            if len(swapped) != len(changes):\n",
    "                continue\n",
    "            \n",
    "            for num_of_p in range(len(swapped)):\n",
    "                new_authors = 1 if changes[num_of_p] == 0 else 2\n",
    "                new_changes = [changes[num_of_p]]\n",
    "                create_new_file(\n",
    "                    augmented_dir, \n",
    "                    swapped[num_of_p], \n",
    "                    create_json_metadata(new_authors, new_changes))\n",
    "            \n",
    "            jumped = jump_same_author_paragraphs(text, metadata)\n",
    "            for num_of_p in range(len(jumped)):\n",
    "                create_new_file(\n",
    "                augmented_dir,\n",
    "                jumped[num_of_p],\n",
    "                create_json_metadata(1, [0]))\n",
    "                \n",
    "            combined = combine_all_different_author_paragraphs(text, metadata)\n",
    "            for num_of_p in range(len(combined)):\n",
    "                create_new_file(\n",
    "                augmented_dir,\n",
    "                combined[num_of_p],\n",
    "                create_json_metadata(2, [1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b5f17aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/easy/train/problem-100.txt\n",
      "./data/easy/train/problem-100.txt\n",
      "./data/easy/train/problem-100.txt\n",
      "./data/easy/train/problem-100.txt\n",
      "./data/easy/train/problem-100.txt\n",
      "./data/easy/train/problem-100.txt\n"
     ]
    }
   ],
   "source": [
    "perform_data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866a870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
